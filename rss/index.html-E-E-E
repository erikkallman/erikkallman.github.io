<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Black-sky Albedo]]></title><description><![CDATA[Black-sky Albedo]]></description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Black-sky Albedo</title><link>http://localhost:2368/</link></image><generator>Ghost 5.24</generator><lastBuildDate>Wed, 04 Dec 2024 09:31:15 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Distributed Quantum Computing]]></title><description><![CDATA[<p>Massive investments are being made in the European landscape of quantum computing. The question is what frameworks that enable orchestration of calculations to only deploy the most optimal problem formulation on the most suitable piece of hardware. </p><h2 id="problem-statement"><strong>Problem statement</strong></h2><p>As a researcher and innovator in the quantum life-science area, I</p>]]></description><link>http://localhost:2368/distributed-quantum-computing/</link><guid isPermaLink="false">670f7f9a0fff339d68075056</guid><dc:creator><![CDATA[Erik Källman]]></dc:creator><pubDate>Wed, 04 Dec 2024 09:20:38 GMT</pubDate><media:content url="http://localhost:2368/content/images/2024/10/Screenshot-2024-10-16-at-13.03.05.png" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2024/10/Screenshot-2024-10-16-at-13.03.05.png" alt="Distributed Quantum Computing"><p>Massive investments are being made in the European landscape of quantum computing. The question is what frameworks that enable orchestration of calculations to only deploy the most optimal problem formulation on the most suitable piece of hardware. </p><h2 id="problem-statement"><strong>Problem statement</strong></h2><p>As a researcher and innovator in the quantum life-science area, I want to be able to develop or test an algorithm locally on my laptop and iteratively expand on it in terms of parameters, noise models used, systems analysed etc. I want to define a grid of parameters, something like:</p><!--kg-card-begin: markdown--><pre><code class="language-python">hyperparam_grid = [
    {
        &apos;optimizer_type&apos;: &apos;COBYLA&apos;,
        &apos;optimizer_steps&apos;: 50,
        &apos;tol&apos;: 1e-3
    },
    {
        &apos;optimizer_type&apos;: &apos;SPSA&apos;,
        &apos;optimizer_steps&apos;: 50,
        &apos;learning_rate&apos;: 0.1
    },
    ...
]</code></pre>
<!--kg-card-end: markdown--><p>over which i want to find the optimal combination with respect to evaluation criteria. From this, a test deployment on a actual quantum computer backend would be made. I would then like to collect details on the calculation and build a &quot;profile&quot; of calculations over different European compute backends. </p><p>Moreover, ideally I would like to be able to create workflows where i can use whatever code i like for calculating integrals and different pieces of data required for my calculations and that parts of these workflows can be executed in parallell over processes that are interdependent. &#xA0;In pseudo-pseudo code:</p><!--kg-card-begin: markdown--><h4 id="define">Define:</h4>
<ul>
<li><code>ansatz_types = [&apos;TwoLocal&apos;, &apos;EfficientSU2&apos;]</code></li>
<li><code>optimizers = [&apos;COBYLA&apos;, &apos;SPSA&apos;]</code></li>
<li><code>hyperparams_list = [{&apos;optimizer_steps&apos;: 10, &apos;optimizer_params&apos;: {&apos;tol&apos;: 1e-3}}, ... ]</code></li>
<li><code>noise_models = [&apos;depolarizing&apos;, &apos;bit_flip&apos;]</code></li>
</ul>
<h4 id="for-each-ansatztype">For each <code>ansatz_type</code>:</h4>
<ul>
<li>Create and append <code>ansatz_spec</code> (function: <code>prepare_ansatz</code>, dependencies: <code>[&quot;assemble_hamiltonian&quot;]</code>)</li>
</ul>
<h4 id="for-each-optimizer">For each <code>optimizer</code>:</h4>
<ul>
<li>Set <code>vqe_dependencies = [&quot;prepare_ansatz_&lt;ansatz_type&gt;&quot;]</code></li>
<li>Create <code>nodename_prefix = &quot;run_vqe_&lt;ansatz_type&gt;_&lt;optimizer&gt;&quot;</code></li>
</ul>
<h4 id="for-each-hyperparams">For each <code>hyperparams</code>:</h4>
<ul>
<li>Create and append <code>vqe_spec</code> (function: <code>run_vqe_simulation</code>, dependencies: <code>vqe_dependencies</code>, optimizer: <code>optimizer</code>, hyperparams: <code>hyperparams</code>)</li>
<li>Set <code>noise_dependencies = [vqe_spec.node_name]</code></li>
<li>Create <code>noise_nodename_prefix = &quot;apply_noise_&lt;vqe_spec.node_name&gt;&quot;</code></li>
</ul>
<h4 id="for-each-noisemodel">For each <code>noise_model</code>:</h4>
<ul>
<li>Create and append <code>noise_spec</code> (function: <code>apply_noise_model</code>, dependencies: <code>noise_dependencies</code>, noise_model: <code>noise_model</code>, ansatz_type: <code>ansatz_type</code>)</li>
</ul>
<!--kg-card-end: markdown--><p>Such that for each wavefunction anzats we get a workflow of dependencies according to:</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2024/10/quantum_workflow_graph_neat_highres-1.png" class="kg-image" alt="Distributed Quantum Computing" loading="lazy" width="1483" height="1067" srcset="http://localhost:2368/content/images/size/w600/2024/10/quantum_workflow_graph_neat_highres-1.png 600w, http://localhost:2368/content/images/size/w1000/2024/10/quantum_workflow_graph_neat_highres-1.png 1000w, http://localhost:2368/content/images/2024/10/quantum_workflow_graph_neat_highres-1.png 1483w" sizes="(min-width: 720px) 720px"></figure><p>Where the hamiltonian is assembled for the particular system and calculation in mind, preferably in a manner where the one and two electron integrals can be calculated using a code of choice.</p><h2 id="solution"><strong>Solution</strong></h2><p><a href="https://ar5iv.labs.arxiv.org/html/2403.16486">ColonyOS</a> is a meta-operating system that simplifies the execution of workloads across diverse and distributed computing environments, including cloud, edge, HPC, and IoT. This makes it ideal for managing the complex, resource-intensive tasks associated with distributed quantum computing. It is Open Source Software (MIT License) and is <a href="https://github.com/colonyos/colonies">available on github</a> for inspection and download. There are some <a href="https://github.com/colonyos/tutorials">great tutorial notebooks</a> to get started.<br><br>ColonyOS supports:</p><h3 id="distributed-microservice-architectures">Distributed Microservice Architectures</h3><p>ColonyOS is built on a microservices model, where small, independent executors handle specific tasks. This approach supports the distributed nature of quantum computing, where quantum tasks (e.g., operations on quantum processors) may need to be executed across geographically separated quantum and classical computing resources. Executors are deployed independently and scaled horizontally, ensuring efficient parallel processing and fault tolerance.</p><h3 id="workflow-orchestration">Workflow Orchestration</h3><p>The platform allows users to define complex, multi-step workflows across distributed executors. This is crucial for quantum computing workflows, which often involve iterative processes like quantum circuit execution, optimization steps (e.g., in VQE algorithms), and hybrid quantum-classical computations. ColonyOS manages the dependencies and execution order, ensuring smooth operation across different systems.</p><h3 id="scalability-and-fault-tolerance">Scalability and Fault Tolerance</h3><p>Quantum computing systems require robust fault tolerance due to the probabilistic nature of quantum states and the potential for node failures in distributed setups. ColonyOS supports automatic re-assignment of tasks to healthy executors if one fails, making it highly resilient to issues that might disrupt quantum computation across distributed nodes.</p><h3 id="platform-agnostic-integration">Platform-Agnostic Integration</h3><p>ColonyOS&#x2019;s ability to operate across various platforms, including cloud and HPC environments, aligns with the hybrid quantum-classical infrastructure often required for quantum computing. This allows ColonyOS to orchestrate tasks that need to run on both classical supercomputers and quantum processors.</p><p>In summary, ColonyOS&apos;s distributed architecture, task orchestration capabilities, scalability, and fault tolerance make it a strong choice for managing the complexities of distributed quantum computing, where tasks need to be efficiently coordinated across a range of quantum and classical computing environments.</p><h2 id="implementation"><strong>Implementation</strong></h2><p>The attempt made in this post is to describe the use of ColonyOS as an orchestrator for quantum computation tasks. The focus is on solving a simpler problem (a water ground state energy calculation) to illustrate the potential of the orchestrator and what it could mean for the distributed aspects of quantum computing. </p><h3 id="what-is-measured-to-evaluate-the-calculations">What Is Measured to Evaluate the Calculations</h3><p>Besides runtimes and ground state energy values generated from the calculations,, estimating how noise affects quantum circuits is important. To evaluate the performance of quantum circuits under noisy conditions, there are numerous metrics that can be used. In the present work the implementation covers <strong>Shannon Entropy</strong> and <strong>Jensen-Shannon Divergence (JSD) </strong>as a starting point. A few sections below will be used to elaborate on this using qiskit as a reference.</p><h4 id="noise-modeling-in-qiskit">Noise Modeling in Qiskit</h4><p><strong>Qiskit</strong> provides various tools for simulating quantum circuits under various noise models. In this context, two common noise models are employed and described below.</p><h5 id="1-depolarizing-noise-model">1. Depolarizing Noise Model</h5><p>The depolarizing noise model represents a scenario where the quantum state loses its coherence and becomes a completely mixed state with a certain probability. Mathematically, for a single-qubit state \(\rho\), the depolarizing channel \(\mathcal{E}_{\text{dep}}\) is defined as:</p><p>\[ \mathcal{E}_{\text{dep}}(\rho) = (1 - p) \rho + p \frac{I}{2} \]where:</p><ul><li>\(p\) is the depolarizing probability (error rate),</li><li>\(I\) is the identity matrix representing the maximally mixed state.</li></ul><p>For multi-qubit systems, the depolarizing channel generalizes by applying the noise independently to each qubit or collectively to the entire system, depending on the model specifics.</p><p>In Qiskit, the depolarizing noise is added to quantum gates like single-qubit rotations (<code>u3</code>) and two-qubit gates (<code>cx</code>) using the <code>depolarizing_error</code> function:</p><pre><code class="language-python">depolarizing_error_1q = noise.depolarizing_error(p, 1)
depolarizing_error_2q = noise.depolarizing_error(p, 2)
</code></pre><p>Every gate operation is followed by the application of the depolarizing channel \(\mathcal{E}_{\text{dep}}\) with a specified probability. This simulates the randomization of the qubit state due to interactions with the environment.</p><p>For example, after applying a gate \(U\), the state \(\rho&apos;\) becomes:</p><p>$$\rho&apos; = \mathcal{E}_{\text{dep}}(U \rho U^\dagger) = (1 - p) U \rho U^\dagger + p \frac{I}{2}$$</p><p>This process increases the mixedness of the quantum state, leading to higher entropy in the output distribution.</p><h5 id="2-bit-flip-noise-model">2. Bit-Flip Noise Model</h5><p>The bit-flip noise model simulates the error where a qubit flips its state from \(|0\rangle\) to \(|1\rangle\) or vice versa, akin to a classical bit flip. The bit-flip channel \(\mathcal{E}_{\text{bf}}\) for a single qubit is defined as:</p><p>$$\mathcal{E}_{\text{bf}}(\rho) = (1 - p) \rho + p X \rho X^\dagger$$</p><p><strong>where</strong></p><ul><li>\(X\) is the Pauli-X operator.</li><li>\(p\) is the probability of a bit-flip error.</li></ul><p>In the context of two-qubit gates, an error might flip both qubits simultaneously, represented by: $$ X \otimes X $$</p><p>In Qiskit, bit-flip errors are introduced using the <code>pauli_error</code> function:</p><pre><code class="language-python">bit_flip_error_1q = noise.pauli_error([(&apos;X&apos;, p), (&apos;I&apos;, 1 - p)])
bit_flip_error_2q = noise.pauli_error([(&apos;XX&apos;, p), (&apos;II&apos;, 1 - p)])
</code></pre><p>In this model, the qubit state is flipped with a certain probability after each gate operation. The effect on the state \(\rho\) is:</p><p>$$\rho&apos; = \mathcal{E}_{\text{bf}}(U \rho U^\dagger) = (1 - p) U \rho U^\dagger + p X U \rho U^\dagger X^\dagger$$</p><p>This introduces specific errors corresponding to bit flips, altering the probabilities of measuring certain outcomes, and thereby changing the output distribution.</p><p>By analyzing the noise output distributions from the simulations one should be able to analyse how:</p><ul><li><strong>Depolarizing Noise</strong> tends to make the distribution more uniform due to the randomization of states, leading to a higher entropy increase.</li><li><strong>Bit-Flip Noise</strong> causes specific transitions between states, resulting in a redistribution of probabilities that may not uniformly increase entropy but can significantly change the distribution shape, as captured by the JSD.</li></ul><h4 id="measuring-the-impact-of-noise">Measuring the Impact of Noise</h4><p>To quantify how noise affects the quantum circuit, we analyze the output probability distributions of the circuit under noiseless and noisy conditions using the following metrics:</p><h5 id="shannon-entropy">Shannon Entropy</h5><p>Shannon Entropy measures the uncertainty or randomness in a probability distribution. For a discrete random variable with possible outcomes \({x_i}\) and corresponding probabilities \({p_i}\), the Shannon entropy \(H\) is defined as:</p><p>$$H(X) = -\sum_{i} p_i \log_2 p_i$$</p><p>In the context of quantum circuits, the entropy of the output distribution indicates how spread out the measurement outcomes are:</p><ul><li><strong>Low Entropy</strong>: The distribution is concentrated on specific outcomes, implying less uncertainty.</li><li><strong>High Entropy</strong>: The distribution is more uniform, indicating higher uncertainty and randomness, often due to noise.</li></ul><p>By calculating the entropy of both the noiseless \(H_{\text{noiseless}}\) and noisy \(H_{\text{noisy}}\) output distributions, we can assess the increase in uncertainty introduced by noise.</p><h5 id="jensen-shannon-divergence-jsd">Jensen-Shannon Divergence (JSD)</h5><p>The <strong>Jensen-Shannon Divergence</strong> is a method of measuring the similarity between two probability distributions. It is a symmetrized and smoothed version of the Kullback-Leibler divergence and is always bounded between 0 and 1 when using log base 2.</p><p>For two probability distributions \(P = {p_i}\) and \(Q = {q_i}\), the JSD is defined as:</p><p>$$\text{JSD}(P \parallel Q) = \frac{1}{2} D_{\text{KL}}(P \parallel M) + \frac{1}{2} D_{\text{KL}}(Q \parallel M)$$</p><p>where:</p><ul><li>\(M = \frac{1}{2}(P + Q)\) is the average distribution, &#xA0;</li><li>\(D_{\text{KL}}(P \parallel M)\) is the Kullback-Leibler divergence from \(P\) to \(M\):</li></ul><p>$$D_{\text{KL}}(P \parallel M) = \sum_{i} p_i \log_2 \left( \frac{p_i}{m_i} \right)$$</p><p>The JSD effectively measures how much the noisy distribution deviates from the noiseless distribution:</p><ul><li><strong>JSD = 0</strong>: The distributions are identical.</li><li><strong>Higher JSD Values</strong>: Indicate greater divergence between the distributions due to noise.</li></ul><h4 id="applying-the-metrics-to-evaluate-noise-impact">Applying the Metrics to Evaluate Noise Impact</h4><p>By computing the Shannon entropy and JSD for the output distributions, we gain quantitative insights into the noise&apos;s effect:</p><p><strong>Entropy Difference (\(\Delta H\)):</strong></p><p>$$\Delta H = H_{\text{noisy}} - H_{\text{noiseless}}$$</p><p><strong>Interpretation:</strong> A positive \(\Delta H\) suggests that noise has increased the uncertainty in the output distribution.</p><p><strong>Entropy Ratio:</strong></p><p>$$\text{Entropy Ratio} = \frac{H_{\text{noisy}}}{H_{\text{noiseless}}}$$</p><p><strong>Interpretation</strong>: Provides a relative measure of entropy increase.</p><p><strong>Jensen-Shannon Divergence</strong>:</p><ul><li>Directly compares the noisy and noiseless distributions, highlighting the overall change in distribution shape.</li></ul><h4 id="practical-implications-of-the-metrics">Practical Implications of the Metrics</h4><ul><li><strong>Algorithm Performance</strong>: Lower entropy difference and JSD values imply that the quantum circuit&apos;s performance is closer to the ideal case, with noise having a minimal effect.</li><li><strong>Noise Model Assessment</strong>: By comparing metrics across different noise models (depolarizing vs. bit-flip), we can evaluate which types of noise have more detrimental effects on the circuit.</li><li><strong>Optimization Strategies</strong>: Understanding how specific noise types impact the circuit guides the development of error mitigation techniques and circuit optimization.</li></ul><h3 id="ranking-and-the-calculation-graph">Ranking and the Calculation Graph</h3><p>The ColonyOS workflow calculation serializes qiskit objects as well as metrics and metadata from each part of the workflow into a sqlite database. This database is then exposed to localhost by a simple Flask API. That flask API is connected to a React frontend that exposes to key views of the results data, detailed below. Both views show the same data and allow ranking across a set of metrics, but do so in different ways.</p><h4 id="the-metrics-table">The Metrics table</h4><p>The metrics table is a simple (in development) table that simply displays each noise simulation computation and data from its related VQE simulation.</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2024/12/Screenshot-2024-12-03-at-14.07.22.png" class="kg-image" alt="Distributed Quantum Computing" loading="lazy" width="2000" height="962" srcset="http://localhost:2368/content/images/size/w600/2024/12/Screenshot-2024-12-03-at-14.07.22.png 600w, http://localhost:2368/content/images/size/w1000/2024/12/Screenshot-2024-12-03-at-14.07.22.png 1000w, http://localhost:2368/content/images/size/w1600/2024/12/Screenshot-2024-12-03-at-14.07.22.png 1600w, http://localhost:2368/content/images/size/w2400/2024/12/Screenshot-2024-12-03-at-14.07.22.png 2400w" sizes="(min-width: 720px) 720px"></figure><h4 id="the-workflow-graph">The Workflow Graph</h4><p>The workflow graph shows how each step in the workflow is connected and which steps are dependent on its information. </p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2024/12/Screenshot-2024-12-03-at-14.19.04.png" class="kg-image" alt="Distributed Quantum Computing" loading="lazy" width="2000" height="962" srcset="http://localhost:2368/content/images/size/w600/2024/12/Screenshot-2024-12-03-at-14.19.04.png 600w, http://localhost:2368/content/images/size/w1000/2024/12/Screenshot-2024-12-03-at-14.19.04.png 1000w, http://localhost:2368/content/images/size/w1600/2024/12/Screenshot-2024-12-03-at-14.19.04.png 1600w, http://localhost:2368/content/images/size/w2400/2024/12/Screenshot-2024-12-03-at-14.19.04.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Here, the legend tells what part of the calculation workflow the nodes correspond to, and a node information panel displays metrics of the selected node. It allows one to compute a ranking across nodes (similar to the metrics table) and rescales as well as labels the nodes as a function of rank, as can be seen below.</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2024/12/Screenshot-2024-12-03-at-14.20.18.png" class="kg-image" alt="Distributed Quantum Computing" loading="lazy" width="2000" height="990" srcset="http://localhost:2368/content/images/size/w600/2024/12/Screenshot-2024-12-03-at-14.20.18.png 600w, http://localhost:2368/content/images/size/w1000/2024/12/Screenshot-2024-12-03-at-14.20.18.png 1000w, http://localhost:2368/content/images/size/w1600/2024/12/Screenshot-2024-12-03-at-14.20.18.png 1600w, http://localhost:2368/content/images/size/w2400/2024/12/Screenshot-2024-12-03-at-14.20.18.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>While this is interesting and useful for smaller calculation like this, one can imagine what such a database could present if the graph could provide easily searchable sets of data. Graph structures readily fit into graph learning algorithms as well, opening up the possibility of predicting calculation graph result estimates based on input to get a first order approximation of what may be good parameters to explore for the given system.</p><h3 id="summary">Summary</h3><p>The ambition of this was to show what is work in progress in terms of using a state of the art orchestrator for distributed computing for the use case of quantum computation. Furthermore, to use graph data analytics to view and analyse computation results. Future work remains to be published.<br><br>For a presentation on ColonyOS and what specific problems it is meant to solve check out this presentation that i held at the <a href="https://enccs.github.io/qas2024/">Quantum Autumn School 2024</a>.</p><hr><p><strong>References:</strong></p><ol><li>Nielsen, M. A., &amp; Chuang, I. L. (2010). <em>Quantum Computation and Quantum Information</em>. Cambridge University Press.</li><li><a href="https://qiskit.github.io/qiskit-aer/apidocs/aer_noise.html">Qiskit Documentation for noise modules in Aer</a></li><li>Shannon, C. E. (1948). A Mathematical Theory of Communication. <em>Bell System Technical Journal</em>, 27(3), 379&#x2013;423.</li></ol><h3></h3>]]></content:encoded></item><item><title><![CDATA[The Sen2cor Processing Handbook]]></title><description><![CDATA[<p>This post is work in progress. You have been warned!</p><h2 id="introduction">Introduction</h2><p>The aim of me writing this document is for anyone with little prior knowledge of sentinel-2 data and its processing to learn all they need to know in order to get started working with it, and in particular the</p>]]></description><link>http://localhost:2368/containerized-sen2cor-processing/</link><guid isPermaLink="false">638e13b3ff4fb9950edd04ac</guid><dc:creator><![CDATA[Erik Källman]]></dc:creator><pubDate>Tue, 13 Dec 2022 16:06:14 GMT</pubDate><content:encoded><![CDATA[<p>This post is work in progress. You have been warned!</p><h2 id="introduction">Introduction</h2><p>The aim of me writing this document is for anyone with little prior knowledge of sentinel-2 data and its processing to learn all they need to know in order to get started working with it, and in particular the generation of an L2A product using the sen2cor processor. What that means should not be obvious to the reader. If it is, perhaps you can still gain some knowledge in skimming through the text, as I will try to explain a number of terms and concepts that are sources of confusion and are typically dropped into the litterature without much further explanation. <br><br>The text is written informally to be easy to digest, and Im hoping that in the end it will serve as the reference point that I would have liked to have put under my nose when first venturing into the space of earth observation.</p><p>To understand what we need to do in order to reach the level-2 A product starting from the raw satellite output, it is first neccessary to review what steps are involved in producing the level-1 input product from the &quot;raw&quot; level-0 data. We need to get some basics covered. What the sensor measures and how its ability to do those measurements is quantified is described briefly in the follwing two subsections. See these sections as building a common vocabulary for the later sections. </p><h3 id="resolution-metrics">Resolution metrics</h3><p>Firstly we will briefly talk about the metrics by which we measure resolution of data obtained and derived from the satellite sensors.</p><p><strong>Spatial resolution </strong>in the context of the sentinel instruments is the area of ground covered by a single pixel. While this may be obvious, that this resolution is <a href="https://sentinels.copernicus.eu/web/sentinel/user-guides/Sentinel-2-msi/resolutions/spatial">wavelength dependent </a>may not be. Additionally, each band is measured in one spatial resolution only, but can of course be up or downsampled to the users liking with the product on hand.</p><p>This term should not be confused with <a href="https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2/instrument-payload/resolution-and-swath"><strong>spectral resolution</strong></a>, which measures the ability of an instrument to resolve a particular part of the electromagnetic spectrum. This is also wavelength dependent, and an instrument never measures at a singular wavelength value but rather always over a bandwidth in a certain range, for a certain spatial resolution and wavelength.</p><p>Sentinel-2 is a set of two satellites - a &quot;constellation&quot;. While this constellation consists of sensor platforms that are similar, they are not identical in exactly what wavelengths they measure (see table below as an example for the difference between the two satellites in the sentinel 2 constellation).</p><!--kg-card-begin: html--><table xmlns="http://www.w3.org/1999/xhtml" dir="ltr" style="table-layout:fixed;font-size:10pt;font-family:Arial;width:0px;border-collapse:collapse;border:none" cellspacing="0" cellpadding="0" border="1"><colgroup><col width="157"><col width="110"><col width="138"><col width="147"></colgroup><tbody><tr style="height:21px;"><td style="border-top:1px solid #000000;border-right:1px solid #000000;border-bottom:1px solid #000000;border-left:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;font-weight:bold;text-align:center;" rowspan="2" colspan="1" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Spatial Resolution\n (m)&quot;}"><span><div style="max-height:42px">Spatial Resolution<br> (m)</div></span></td><td style="border-top:1px solid #000000;border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;font-weight:bold;text-align:center;" rowspan="2" colspan="1" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Band Number&quot;}"><span><div style="max-height:42px">Band Number</div></span></td><td style="border-top:1px solid #000000;border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;font-weight:bold;text-align:center;" rowspan="1" colspan="2" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;S2A, S2B difference (abs)&quot;}">S2A, S2B difference (abs)</td></tr><tr style="height:21px;"><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;font-weight:bold;text-align:center;" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Central Wavelength\n (nm)&quot;}">Central Wavelength<br> (nm)</td><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;font-weight:bold;text-align:center;" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Bandwidth\n (nm)&quot;}">Bandwidth<br> (nm)</td></tr><tr style="height:21px;"><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;border-left:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" rowspan="4" colspan="1" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10}"><span><div style="max-height:84px">10</div></span></td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2}">2</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2999999999999545}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.3</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3}">3</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.7999999999999545}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.8</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4}">4</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2999999999999545}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.3</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8}">8</td><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.10000000000002274}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.1</td><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;border-left:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" rowspan="6" colspan="1" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20}"><span><div style="max-height:126px">20</div></span></td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5}">5</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3000000000000682}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.3</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">1</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6}">6</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1.3999999999999773}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">1.4</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7}">7</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.099999999999909}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">3.1</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;8a&quot;}">8a</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.7000000000000455}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.7</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">1</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11}">11</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.2999999999999545}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">3.3</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">3</td></tr><tr style="height:21px;"><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12}">12</td><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:16.700000000000273}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">16.7</td><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">10</td></tr><tr style="height:21px;"><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;border-left:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" rowspan="3" colspan="1" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:60}"><span><div style="max-height:63px">60</div></span></td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}">1</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.5}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0.5</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">0</td></tr><tr style="height:21px;"><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9}">9</td><td style="overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1.8999999999999773}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">1.9</td><td style="border-right:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">1</td></tr><tr style="height:21px;"><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:center;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10}">10</td><td style="border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.400000000000091}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">3.4</td><td style="border-right:1px solid #000000;border-bottom:1px solid #000000;overflow:hidden;padding:2px 3px 2px 3px;vertical-align:bottom;text-align:right;" data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}" data-sheets-formula="=abs(R[-19]C[0]-R[-19]C[2])">1</td></tr></tbody></table><!--kg-card-end: html--><p>We can observe that the difference in both central wavelength and bandwidth varies between bands, and band 12 at 2190 nm shows a larger deviation. However, since we are already in the short wave infrared part of the spectrum, this deviation is relatively small (about 0.8%). Having a precise measure of the central wavelength gives the ground segment a number to correct for in calculating the radiance values. More on that in the processing section, and the below section on units.</p><p>Note that certain bands are processed only to a certain spatial resolution. We will return to this in later sections where we talk about requesting specific spatial resultions to be produced by sen2cor.</p><p>Finally, there is <strong><a href="https://sentinels.copernicus.eu/web/sentinel/user-guides/Sentinel-2-msi/resolutions/radiometric">radiometric resolution</a></strong>, which measures the range of brightness values that can be recorded by the satellite and is bounded by the interger type - 12 bit in the case of Sentinel-2 - used to store the data which limits it to integers between 0 to 4095. This can be thought of as the &quot;dynamic range&quot; in photography terms.</p><h3 id="units">Units</h3><p>As hinted at in the resolution section above, the radiance values (energy flux) recorded at the sensor are rescaled into a digital representation from a unit often measured in watt/(steradian/square meter). Steradian, or &quot;square radian&quot; here being the SI unit for volumetric angles compared to the radian being the unit for planar angles. </p><p>To make this perfectly clear: one radian unit of angle represents the angle in planar section of a circle where the circumference cut of the circle is equal to its radius. Correspondingly, the one steradian represents the volumetric element where the surface area of a cone is a circle of area radius^2. So nothing more exotic than a radian in three dimensions (how can we genereralize the radian to four, or five dimensions?).</p><p>Note that the digital number resulting in a derived radiance value is taken at sensor level - there is no separation of radiance sources (atmosphere, land objects, etc) in the recording of the data. Any diffuse medium between the land object and the sensor (a cloud for instance) will &#xA0;diminish the radiance contribution from that object and render it more diffusely. More on this, and other correction steps, in later sections where we discuss data processing.</p><p>Reflectance should not be confused with Radiance, in that it is the ratio of the quantity of radiation reflected from a target to the radiation incident on the target. Therefore it is unitless and depends directly on the material being observed.</p><p>These two terms - reflectance and radiance - are sometimes used interchangebly and in others with minor variations depending on the physics of the system being observed. In both cases it is worth remembering that the sensor doesnt measure either of them but rather the energy flux incident on the sensor, which can then be converted (or re-scaled) to an unsigned interger that represents the physical variable.</p><h2 id="sentinel-2-data-processing">Sentinel 2 data processing</h2><p>The sections below detail the different steps or processing levels that the raw data from the satellite is subject to after having been recieved at the ground station. </p><p>There is always error in physical measurements, and we will start by considering the sources of error or image distortion that apply to satellite data. In general terms there are four categories of sources for satellite image distortion, and they are briefly described below.</p><h4 id="the-sensor">The sensor </h4><p>The digital output from the sensor deployed on the satellite is subject to degradation, as well as minute mechanical differences for a type of sensor in a production series. Therefore, it is not suitable to use the raw output from them as spectral measures. Instead they must be scaled into a number of a certain bit depth by using suitable calibration coefficients. This process converts digital sensor numbers to what is typically refered to in the litterature as <strong>at-sensor radiance. </strong>This is different from sensor calibration, which is the process of modelling sensor degradation and deriving calibrations coefficients as a function of sensor usage over time.</p><h4 id="the-sun">The sun</h4><p>Once the at-sensor radiance values are obtained, the next step would account for solar radiation interference and earth-sun geometry, which is dependent on latitude and datum, to obtain values of top-of-atmosphere (TOA) reflectance. The effect of this source of distortions depend on solar power (which varies over time), the solar elevation angle (determining the amount of light reflected) and the Earth-Sun distance (which also varies over time). </p><p>Thankfully, while solar flux can be a complicated process to model depending on the need for detail, the Earth and the Sun are reasonably well-behaved celestial bodies and the geometric relationships between them are easily calculated. It is worth noting that in some litterature, correcting for this is sometimes grouped together with the sensor correction step.</p><h4 id="the-atmosphere">The atmosphere</h4><p></p><h4 id="top-of-atmosphere-radiance">Top of Atmosphere Radiance</h4><p>Radiation, both from terrestial and interstellar sources, has varying probability of scattering in parts of the volume segment from the surface of the earth to the sensor platform of the satellite. As such, the observed radiation is a superposition of all of those scattering processes distributed over space and wavelength. What that mix of scattered radiation consists of depends on a great variety of physical processes - Rayleigh scattering in the atmosphere, for instance, results in a large part of the blue region of the visible spectrum scattering in the atmosphere.</p><p>Knowing what processes and types of radiation yield what type of scattering allows us to selectively correct for certain regions. Removing the scattered light in the atmosphere and only preserving the surface contribution provides a bottom of atmosphere (BOA) corrected product, and the inverse is true for the top of atmopshere (TOA) variation. However, simply knowing that a data product has been TOA or BOA corrected is no enough since there are many ways of caluculating those values. The user is adviced to read up on what kind of correction has been applied, before using the data in their analysis.</p><p>Reflectance is dimensionless because radiance is divided by irradiance so the units cancel. However (and this confuses many people) reflectance is not constrained to fall between 0-1; sometimes it is stored in integer format (e.g. 12-bit or 16- bit) because floating point format (0-1) takes up too much disk space. If you have pixel values of 1000 then the data can certainly be in top-of-atmosphere or surface reflectance. However, you need to look at the metadata and/or read the data description to be certain what level of processing the data had. Do not look at the data and try to make guesses about the processing - the level of processing is explained in the data documentation.If you are using Landsat climate data record (CDR) data then it is mostly in surface reflectance but it needs to be slightly rescaled as well as have a sun angle correction applied. If the data was distributed as TOA reflectance then the radiance at the Landsat sensor was divided by the exo-atmospheric irradiance and this is better than nothing but there will be band-specific biases (according to Rayleigh scattering).</p><hr><p>The energy that is captured by Landsat sensors is influ- enced by the Earth&#x2019;s atmosphere. These effects include scattering and absorption due to interactions of the elec- tromagnetic radiation with atmospheric particles (i.e.,gases, water vapor, and aerosols)</p><p>However, some atmospheric effects are highly variable over the Earth&#x2019;s surface and can be difficult to correct in Landsat imagery. While it is not always necessary to atmospherically correct Landsat data to surface values, there are instances where this level of correction is needed. In general, absolute atmospheric corrections are needed when (1) an empirical model is being created for application beyond the data used to develop it, (2) there is a comparison being made to ground reflectance data such as a field-based spectroradi- ometer, or (3) as an alternative to relative correction when comparisons are being made across multiple images. All atmospheric correction methods have associated assump- tions about the target and the nature of the atmospheric particles or emissivity (for land surface temperature). There are numerous atmospheric correction methods available, ranging from simple approaches that use only within-image information such as dark object subtraction (Chavez 1988), to more complex and data-intensive approaches such as the method used for the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) products (Masek et al. 2006)</p><h4 id="the-topography">The topography</h4><p>while others specifically address potential artifacts (e.g., topographic correction).</p><p>The processes of georeferencing (alignment of imagery to its correct geographic location) and orthorectifying (correction for the effects of relief and view direction on pixel location) are components of geometric correction necessary to ensure the exact positioning of an image. Imagery can be positioned relative to the datum, topog- raphy, or other data types, including reference data and additional geospatial layers that might be used in the analyses.</p><p>Discrepancies should be corrected prior to analysis using a process known as co-registration (often referred to as just registration). Registration involves aligning data layers relative to one another, while georef- erencing involves aligning layers to the correct geographic location. Registration is a critical step in preprocessing Landsat imagery for ecological analysis, since a misregis- tration can result in significant errors, especially in change detection analyses (Sundaresan et al. 2007). When relating Landsat data to ancillary georeferenced data, such as GPS-marked plot data, images should be georeferenced rather than registered to maintain alignment between data. There are numerous approaches for both georefer- encing and registering Landsat data, and the process might involve a simple pixel shift or a more complex auto- mated feature detection and matching between images (for review, see Brown 1992, Zitova&#x301; and Flusser 2003).</p><p>Solar correction does not account for illumination effects from slope, aspect, and elevation that can cause variations in reflectance values for similar features with different terrain positions (Rian&#x303;o et al. 2003). Topographic correction is the process used to account for these effects. While this correction is not always required, it can be especially important for applications in mountain systems or rugged terrain (Colby 1991, Rian&#x303;o et al. 2003, Shepherd and Dymond 2003), which are common settings for sat- ellite monitoring due to the difficulty of accessing these environments for field measurements.</p><p>An important distinction should be made between top- ographic and terrain correction. Topographic correction is a radiometric process while terrain correction is geometric in nature. Although Landsat Level-1 products are terrain corrected, this does not account for the same effects as a topographic correction. Terrain correction ensures each pixel is displayed as viewed from directly above regardless of topography or view angle, and, while important, does not account for the same effects as top- ographic correction.</p><p>While this preproc- essing step can be more important than atmospheric correction for some applications in topographically complex regions (Vanonckelen et al. 2013), this step is not needed for every scenario.</p><p></p><p>Correcting for these they may be computationally costly and the corrections themselves are imperfect. They may introduce artifacts in the data, for instance, or only partially capable of correcting for the effect they are designed for. The correction for these distortions and how they are adressed are often mentioned in bullet-point fashion in documentation, but without much reference, resoning or justification.</p><p> </p><h3 id="level-0"><a href="https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/product-types/level-0">Level-0</a></h3><p>The Sentinel-2 Level 0 product, unlike L1C, is not available for public access and is the first processing level performed by the Payload Data Ground Segment (<a href="https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2/ground-segment/core-ground-segment/pdgs">PDGS</a>). Its processing step takes the MSI raw data as input from th Copernicus <a href="https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2/ground-segment">Ground Segment</a> and ..</p><ul><li>error checks the satellite telemetry data,</li><li>generates a preliminary low-res image and cloudmask for early filtering of data of poor quality,</li><li>dates the individual lines in the recieved image to enable the exact capture time of each ISP within a predefined granule (geographic region) to be recorded,</li><li>packages Instrument Source Packets obtained from the satellite ground station network into granules</li></ul><h3 id="level-0-consolidated">Level-0 Consolidated</h3><p>This intermediary product contains L-0 and all the meta-data required for subsequent L1 processing. These packets of data are compressed and stored. Like the L0 product L0C is not available to the public.</p><h3 id="level-1-a">Level-1 A</h3><p>This processing step refers to the decompression of the L0C product and applies no processing beyond that.</p><h3 id="level-1-b">Level-1 B</h3><p></p><h4></h4><ol><li>Level-1B radiometric processing, including:</li></ol><ul><li>dark signal correction</li><li>pixel response non-uniformity correction</li><li>crosstalk correction</li><li>defective pixels identification</li><li>high spatial resolution bands restoration (de-convolution and de-noising)</li><li>binning of the 60 m spectral bands.</li></ul><ol><li>Resampling on the common geometry grid for registration between the Global Reference Image (GRI) and the reference band (B4 by default).</li><li>Collection of the tie-points from the two images for registration between the GRI and the reference band.</li><li>Tie-points filtering for image-GRI registration: filtering of the tie-points over several areas. A minimum number of tie-points is required.</li><li>Refinement of the viewing model using the initialised viewing model and and Ground Control Points (GCPs). The output refined model ensures registration between the GRI and the reference band.</li><li>Level-1B imagery compression utilises the JPEG2000 algorithm.</li></ol><h3 id="level-1">Level 1</h3><p>&#x200C;&#x200C;Sentinel-2 MSI L1C data undergoes a number of pre-processing steps before it is ready for use. These steps include radiometric and geometric correction, atmospheric correction, and cloud and water masking.&#x200C;&#x200C;&#x200C;&#x200C;&#x200C;&#x200C;&#x200C;&#x200C;DEM <a href="https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/definitions">https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/definitions</a></p><p>Radiometric correction is applied to adjust the data to account for variations in the instrument&apos;s sensitivity and to remove any effects of the atmosphere on the measured radiance.</p><p>Geometric correction is applied to remove any distortion in the image caused by the satellite&apos;s motion and to project the data onto a consistent map projection.</p><p>Atmospheric correction is applied to remove the effects of the atmosphere on the measured radiance. This step is necessary because the atmosphere can cause the measured radiance to be either higher or lower than the actual surface reflectance.</p><p>Cloud and water masking is applied to identify and mask out any clouds or water bodies in the image. This step is necessary because clouds and water can interfere with the analysis of the data.</p><p>Overall, the pre-processing steps applied to Sentinel-2 MSI L1C data are designed to correct for various factors that can affect the quality of the data and to make the data more consistent and usable for various applications.</p><h2 id="outlook-and-advice">Outlook and advice</h2><p>We recommend taking a parsimonious approach to preprocessing; correct the artifacts necessary for a par- ticular application, but avoid unnecessary steps that may introduce additional artifacts without gaining additional value (Song et al. 2001, Rian&#x303;o et al. 2003, Kennedy et al. 2009).</p><p>Sources, further reading:</p><ul><li>Young, Nicholas &amp; Anderson, Ryan &amp; Chignell, Stephen &amp; Vorster, Anthony &amp; Lawrence, Rick &amp; Evangelista, Paul. 2017. <em>A survival guide to Landsat preprocessing</em>. Ecology. 98. 920-932. 10.1002/ecy.1730.</li><li>Gyanesh Chander, Brian L. Markham, Dennis L. Helder. 2009. <em>Summary of current radiometric calibration coefficients for Landsat MSS, TM, ETM+, and EO-1 ALI sensors</em>, Remote Sensing of Environment, Volume 113, Issue 5, Pages 893-903,&#x200C;&#x200C;</li></ul>]]></content:encoded></item></channel></rss>